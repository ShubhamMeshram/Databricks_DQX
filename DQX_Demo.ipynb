{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920fc722-8484-4e46-8a2a-df321403ca4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.labs.dqx.profiler.profiler import DQProfiler\n",
    "from databricks.labs.dqx.profiler.generator import DQGenerator\n",
    "from databricks.labs.dqx.profiler.dlt_generator import DQDltGenerator\n",
    "from databricks.labs.dqx.engine import DQEngine\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import yaml\n",
    "from databricks.labs.dqx.contexts.workspace import WorkspaceContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26cdd117-84c2-445c-8f07-c1a0e5a58e6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the WorkspaceClient to interact with the Databricks workspace\n",
    "ws = WorkspaceClient()\n",
    "\n",
    "# Initialize a DQProfiler instance with the workspace client\n",
    "profiler = DQProfiler(ws)\n",
    "\n",
    "generator = DQGenerator(ws)\n",
    "\n",
    "dq_engine = DQEngine(ws)\n",
    "\n",
    "\n",
    "ws = WorkspaceClient()\n",
    "profiler = DQProfiler(ws)\n",
    "generator = DQGenerator(ws)\n",
    "dlt_generator = DQDltGenerator(ws)\n",
    "dq_engine = DQEngine(ws)\n",
    "\n",
    "input_df = spark.read.csv(\"dbfs:/databricks-datasets/flights/departuredelays.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24f048fa-a0c6-4c77-859c-5b3eb06a2e7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open( \"custom_dqx_rules.yaml\", \"r\") as file:\n",
    "    check_dict = yaml.safe_load(file)\n",
    "\n",
    "dq_engine = DQEngine(spark)\n",
    "validation_result = dq_engine.validate_checks(check_dict)\n",
    "\n",
    "assert not validation_result.has_errors, f\"Validation failed: {validation_result.errors}\"\n",
    "\n",
    "silver_df, quarantine_df = dq_engine.apply_checks_by_metadata_and_split(input_df, check_dict)\n",
    "print(f'Total row count: {input_df.count()}, Good row count: {silver_df.count()}, Quarantined row count: {quarantine_df.count()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796cdb05-338b-448a-b71a-f742ec4b552d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "#input_df = input_df.withColumn(\"destination\", when(col(\"origin\") == \"ANC\", None).otherwise(col(\"destination\")))\n",
    "input_df = input_df.withColumn(\"origin\", when(col(\"destination\") == \"ANC\", None).otherwise(col(\"origin\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3b1e0e3-14d1-4901-bab4-2ab0286c5ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Column\n",
    "from databricks.labs.dqx.row_checks import make_condition\n",
    "\n",
    "def distance_gt_check(col_name):\n",
    "    column = F.col(col_name)\n",
    "    return make_condition(column>3500, f\"Column {col_name} exceeds 3500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea44897c-c77c-4b73-ab3d-7755fdd442c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Column\n",
    "import pyspark.sql.functions as F\n",
    "from databricks.labs.dqx import row_checks\n",
    "from databricks.labs.dqx.row_checks import make_condition\n",
    "from databricks.labs.dqx.rule import DQColRule, DQColSetRule\n",
    "\n",
    "def distance_gt_check(col_name):\n",
    "    column = F.col(col_name)\n",
    "    return make_condition(column>3500, f\"Column {col_name} exceeds 3500\", f\"{col_name}\")\n",
    "\n",
    "Inline_rule_checks = [\n",
    "    DQColRule(name=\"destination_blanks\", col_name=\"destination\", check_func=row_checks.is_not_null_and_not_empty, criticality=\"error\"),\n",
    "    DQColRule(name=\"delay_range\", col_name=\"delay\", check_func=row_checks.is_in_range, criticality=\"warn\", check_func_kwargs={\"min_limit\": -85, \"max_limit\": 1050}),\n",
    "    DQColRule(name=\"distance_gt\", col_name=\"distance\", check_func=distance_gt_check,criticality=\"warn\")\n",
    "] + DQColSetRule(columns=[\"origin\", \"destination\"], criticality=\"error\", check_func=row_checks.is_not_null,).get_rules()\n",
    "\n",
    "valid_and_quarantined_df = dq_engine.apply_checks(input_df, Inline_rule_checks)\n",
    "display(valid_and_quarantined_df.groupBy(col(\"_errors\").isNotNull().alias(\"has_errors\")).count())\n",
    "display(valid_and_quarantined_df.groupBy(col(\"_warnings\").isNotNull().alias(\"has_warnings\")).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e053f125-1706-4117-b15c-c9d8c4b45eed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(valid_and_quarantined_df.withColumn(\"has_errors\", col(\"_errors\").isNotNull()).withColumn(\"has_warnings\", col(\"_warnings\").isNotNull()).groupBy(\"has_errors\", \"has_warnings\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efdcf62b-3b9a-461a-9d2f-72c8ac61f555",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "quality_check_results = dq_engine.run_quality_checks(\n",
    "    table_name=None, # No table_name needed if input_df is passed directly\n",
    "    input_df=input_df, # Pass your DataFrame here\n",
    "    checks=DQColRule_checks\n",
    ")\n",
    "\n",
    "# 2. Get the valid and quarantined DataFrames from the results object\n",
    "valid_df_alt = quality_check_results.get_valid_data()\n",
    "quarantined_df_alt = quality_check_results.get_quarantined_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a69e623c-c835-46e1-b916-d7763d095748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "quarantine_df.limit(1).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "232914ba-2398-4372-9ec5-f3a669c42994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a DQEngine instance with the WorkspaceClient\n",
    "dq_engine = DQEngine(WorkspaceClient())\n",
    "\n",
    "# Apply quality checks and split the DataFrame into silver and quarantine DataFrames\n",
    "silver_df, quarantine_df = dq_engine.apply_checks_by_metadata_and_split(input_df, check_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7064ea1d-22c3-4e3c-b881-7e3613d4bf2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(quarantine_df.count())\n",
    "display(silver_df.count())\n",
    "display(input_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9005e779-28bd-44fc-aef4-a37d11192c60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ctx = WorkspaceContext(WorkspaceClient())\n",
    "dashboards_folder_link = f\"{ctx.installation.workspace_link('https://adb-8333330282859393.13.azuredatabricks.net/')}dashboards/\"\n",
    "print(f\"Open a dashboard from the following folder and refresh it:\")\n",
    "print(dashboards_folder_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "835ba207-20aa-42a3-a153-f24a07e3ee1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the WorkspaceClient to interact with the Databricks workspace\n",
    "ws = WorkspaceClient()\n",
    "\n",
    "# Initialize a DQProfiler instance with the workspace client\n",
    "profiler = DQProfiler(ws)\n",
    "\n",
    "# Read the input data from a Delta table\n",
    "input_df = spark.read.csv(\"dbfs:/databricks-datasets/flights/departuredelays.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Display a sample of the input data\n",
    "input_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b06cd5a1-2452-4aa7-8fcb-347314fe7866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_df = spark.read.csv(\"dbfs:/databricks-datasets/flights/departuredelays.csv\", header=True, inferSchema=True)\n",
    "summary_stats, profiles = profiler.profile(input_df, opts={\"sample_fraction\": 1.0})\n",
    "print(yaml.safe_dump(summary_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d74b4daf-1920-4ff0-bfa0-b2f633dda517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for profile in profiles:\n",
    "    print('*',profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12792f47-5608-426d-9b08-417b27207ab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "generator = DQGenerator(ws)\n",
    "checks = generator.generate_dq_rules(profiles)  # with default level \"error\"\n",
    "print(yaml.safe_dump(checks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50cd20bd-9345-4a76-9b11-5afc33124626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dlt_generator = DQDltGenerator(ws)\n",
    "\n",
    "dlt_expectations = dlt_generator.generate_dlt_rules(profiles, language=\"SQL\")\n",
    "print(dlt_expectations)\n",
    "\n",
    "dlt_expectations = dlt_generator.generate_dlt_rules(profiles, language=\"Python\")\n",
    "print(dlt_expectations)\n",
    "\n",
    "dlt_expectations = dlt_generator.generate_dlt_rules(profiles, language=\"Python_Dict\")\n",
    "print(dlt_expectations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7478356647026157,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "DQX_Demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
